{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model usage\n",
    "## IMPORTANTE: Para ejecutar los notebooks, en la carpeta data aÃ±ada los archivos que puede encontrar en el siguiete drive:\n",
    "https://uniandes-my.sharepoint.com/:f:/g/personal/j_arboleda_uniandes_edu_co/EgEasT6fqDxFmBCiYZYRw0MBG87E7s4hFZuHCzTJ3DAXow?e=ybBMgw\n",
    "## Integrantes\n",
    "* Juan Esteban Arboleda\n",
    "* Luccas Rojas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculo de la perplejidad de cada modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "PATH_NEWS_UNIGRAM=\"../data/20N_l.rojasb_j.arboleda_unigrams.txt\"\n",
    "PATH_BAC_UNIGRAM=\"../data/BAC_l.rojasb_j.arboleda_unigrams.txt\"\n",
    "PATH_NEWS_BIGRAM=\"../data/20N_l.rojasb_j.arboleda_bigrams.txt\"\n",
    "PATH_BAC_BIGRAM=\"../data/BAC_l.rojasb_j.arboleda_bigrams.txt\"\n",
    "PATH_NEWS_TRIGRAM=\"../data/20N_l.rojasb_j.arboleda_trigrams.txt\"\n",
    "PATH_BAC_TRIGRAM=\"../data/BAC_l.rojasb_j.arboleda_trigrams.txt\"\n",
    "\n",
    "PATH_BAC_TEST = \"../data/BAC_l.rojasb_j.arboleda_test.txt\" \n",
    "PATH_NEWS_TEST = \"../data/20N_l.rojasb_j.arboleda_test.txt\"  \n",
    "\n",
    "tokenizer = WhitespaceTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test(path):\n",
    "    \"\"\"\n",
    "    Load test data from a file.\n",
    "    Params\n",
    "    ------\n",
    "    path: str\n",
    "        Path to the file.\n",
    "    Returns\n",
    "    -------\n",
    "    test: list\n",
    "        List of strings.\n",
    "    \"\"\"\n",
    "    test = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            test.append(line.strip())\n",
    "    return test\n",
    "bac_test = load_test(PATH_BAC_TEST)\n",
    "news_test = load_test(PATH_NEWS_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ngram(path: str) -> dict:\n",
    "    ngram_dict = {}\n",
    "    f = open(path, \"r\")\n",
    "\n",
    "    ngram = f.readline()\n",
    "    while(len(ngram) != 0):\n",
    "        ngram = ngram.split(\",\")\n",
    "        ngram_dict[ngram[0]] = {\n",
    "            \"count\": int(ngram[1]),\n",
    "            \"probability\": float(ngram[2])\n",
    "        }\n",
    "        ngram = f.readline()\n",
    "\n",
    "    return ngram_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_unk(words:list,monogram:dict)->list:\n",
    "    \"\"\"\n",
    "    Replace unknown words with <UNK>.\n",
    "    Params\n",
    "    ------\n",
    "    sentence: str\n",
    "        Sentence to be replaced.\n",
    "    Returns\n",
    "    -------\n",
    "    sentence: str\n",
    "        Sentence with <unk>.\n",
    "    \"\"\"\n",
    "    words2 = []\n",
    "    for word in words:\n",
    "        if word not in monogram:\n",
    "            words2.append(\"<UNK>\")\n",
    "        else:\n",
    "            words2.append(word)\n",
    "    return words2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_unigram_perplexity(model, test_data)->float:\n",
    "    \"\"\"    \n",
    "    Calculate the perplexity of a unigram model.\n",
    "    Params\n",
    "    ------\n",
    "    model: dict\n",
    "        Dictionary with the model.\n",
    "    test_data: list\n",
    "        List of strings.\n",
    "    Returns\n",
    "    -------\n",
    "    perplexity: float\n",
    "        Perplexity of the model.\n",
    "    \"\"\"\n",
    "    test_size = len(test_data)\n",
    "    log_sum = 0\n",
    "    for sentence in test_data:\n",
    "        words = tokenizer.tokenize(sentence)\n",
    "        words = replace_unk(words, model)\n",
    "        for word in words:\n",
    "            if word in model:\n",
    "                probability = model[word][\"probability\"]\n",
    "            else:\n",
    "                probability = model[\"<UNK>\"][\"probability\"]\n",
    "            log_sum += math.log2(probability)\n",
    "    return -(1)*(log_sum / test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bigram_perplexity(bigram_model, monogram_model, test_data)->float:\n",
    "    \"\"\"\n",
    "    Calculate the perplexity of a bigram model.\n",
    "    Params\n",
    "    ------\n",
    "    model: dict\n",
    "        Dictionary with the model.\n",
    "    test_data: list\n",
    "        List of strings.\n",
    "    Returns\n",
    "    -------\n",
    "    perplexity: float  \n",
    "        Perplexity of the model.\n",
    "    \"\"\"\n",
    "    test_size = len(test_data)\n",
    "    log_sum = 0\n",
    "    vocabulary = len(monogram_model)\n",
    "    for sentence in test_data:\n",
    "        words = tokenizer.tokenize(sentence)\n",
    "        words = replace_unk(words, monogram_model)\n",
    "        for i in range(len(words)-1):\n",
    "            bi_gram = words[i]+\" \"+words[i+1]\n",
    "            if bi_gram in bigram_model:\n",
    "                probability = bigram_model[bi_gram][\"probability\"]\n",
    "            else:\n",
    "                probability = 1/monogram_model[words[i]][\"count\"]+vocabulary\n",
    "\n",
    "            log_sum += math.log2(probability)\n",
    "    return -1*(log_sum / test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_trigram_perplexity(trigram, bigram_model, monogram_model, test_data)->float:\n",
    "    \"\"\"\n",
    "    Calculate the perplexity of a trigram model.\n",
    "    Params\n",
    "    ------\n",
    "    model: dict\n",
    "        Dictionary with the model.\n",
    "    test_data: list\n",
    "        List of strings.\n",
    "    Returns\n",
    "    -------\n",
    "    perplexity: float  \n",
    "        Perplexity of the model.\n",
    "    \"\"\"\n",
    "    test_size = len(test_data)\n",
    "    log_sum = 0\n",
    "    bigram_size = len(bigram_model)\n",
    "    for sentence in test_data:\n",
    "        words = tokenizer.tokenize(sentence)\n",
    "        words = replace_unk(words, monogram_model)\n",
    "        for i in range(len(words)-2):\n",
    "            tri_gram = words[i]+\" \"+words[i+1]+\" \"+words[i+2]\n",
    "            bi_gram = words[i]+\" \"+words[i+1]\n",
    "            if tri_gram in trigram:\n",
    "                probability = trigram[tri_gram][\"probability\"]\n",
    "            elif bi_gram in bigram_model:\n",
    "                probability = 1/(bigram_model[bi_gram][\"count\"]+bigram_size)\n",
    "            else:\n",
    "                probability = 1/(2*bigram_size)\n",
    "            log_sum += math.log2(probability)\n",
    "    return -1*(log_sum / test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226.18783455162796"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEWS_UNIGRAMS_PATH  = \"../data/20N_l.rojasb_j.arboleda_unigrams.txt\"\n",
    "NEWS_BIGRAM_PATH    = \"../data/20N_l.rojasb_j.arboleda_bigrams.txt\"\n",
    "NEWS_TRIGRAM_PATH   = \"../data/20N_l.rojasb_j.arboleda_trigrams.txt\"\n",
    "\n",
    "unigrams_model = load_ngram(NEWS_UNIGRAMS_PATH)\n",
    "calculate_unigram_perplexity(unigrams_model, news_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157.1078879905547"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_model = load_ngram(NEWS_BIGRAM_PATH)\n",
    "calculate_bigram_perplexity(bigram_model, unigrams_model, news_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296.2412333496441"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_model = load_ngram(NEWS_TRIGRAM_PATH)\n",
    "calculate_trigram_perplexity(trigram_model, bigram_model, unigrams_model, news_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164.02407797343312"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigrams_model = load_ngram(PATH_BAC_UNIGRAM)\n",
    "calculate_unigram_perplexity(unigrams_model, bac_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130.6983538060847"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_model = load_ngram(PATH_BAC_BIGRAM)\n",
    "calculate_bigram_perplexity(bigram_model, unigrams_model, bac_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "trigram_model = load_ngram(PATH_BAC_TRIGRAM)\n",
    "calculate_trigram_perplexity(trigram_model, bigram_model, unigrams_model, bac_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def bigram_predict(first_word: str, model: dict, pprint = False, word_limit = 100) -> str:\n",
    "    first_word = first_word.lower()\n",
    "    fw_in_vocab = False\n",
    "    for words_str in model:\n",
    "        words = words_str.split(\" \")\n",
    "        if first_word == words[0]:\n",
    "            fw_in_vocab = True\n",
    "            break\n",
    "\n",
    "    if fw_in_vocab:\n",
    "        w = first_word\n",
    "    else:\n",
    "        w = \"<UNK>\"\n",
    "    \n",
    "    sentence = \"\"\n",
    "    wcount = 0\n",
    "    while (w != \"</s>\") and (wcount <= word_limit):\n",
    "        sentence += w + \" \"\n",
    "        if pprint:\n",
    "            print(w + \" \", end=\"\")\n",
    "        \n",
    "        # get next word\n",
    "        population = []\n",
    "        weights = []\n",
    "        for words_str in model:\n",
    "            words = words_str.split(\" \")\n",
    "            if words[0] == w:\n",
    "                population.append(words[1])\n",
    "                weights.append(model[words_str][\"count\"])\n",
    "\n",
    "            \n",
    "        w = random.choices(population, weights)[0]\n",
    "        wcount += 1\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_ngram(PATH_BAC_BIGRAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dont know how hard because we copy of prom "
     ]
    },
    {
     "data": {
      "text/plain": [
       "'dont know how hard because we copy of prom '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_predict(\"dont\", model, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
