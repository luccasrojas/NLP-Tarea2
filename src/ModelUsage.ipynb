{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Punto 3 Recuperación ranqueada y vectorización de documentos (RRDV)\n",
    "## Integrantes\n",
    "* Juan Esteban Arboleda\n",
    "* Luccas Rojas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculo de la perplejidad de cada modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "PATH_NEWS_UNIGRAM=\"../data/20N_l.rojasb_j.arboleda_unigrams.txt\"\n",
    "PATH_BAC_UNIGRAM=\"../data/BAC_l.rojasb_j.arboleda_unigrams.txt\"\n",
    "PATH_NEWS_BIGRAM=\"../data/20N_l.rojasb_j.arboleda_bigrams.txt\"\n",
    "PATH_BAC_BIGRAM=\"../data/BAC_l.rojasb_j.arboleda_bigrams.txt\"\n",
    "PATH_NEWS_TRIGRAM=\"../data/20N_l.rojasb_j.arboleda_trigrams.txt\"\n",
    "PATH_BAC_TRIGRAM=\"../data/BAC_l.rojasb_j.arboleda_trigrams.txt\"\n",
    "\n",
    "PATH_BAC_TEST = \"../data/BAC_l.rojasb_j.arboleda_test.txt\" \n",
    "PATH_NEWS_TEST = \"../data/20N_l.rojasb_j.arboleda_test.txt\"  \n",
    "\n",
    "tokenizer = WhitespaceTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test(path):\n",
    "    \"\"\"\n",
    "    Load test data from a file.\n",
    "    Params\n",
    "    ------\n",
    "    path: str\n",
    "        Path to the file.\n",
    "    Returns\n",
    "    -------\n",
    "    test: list\n",
    "        List of strings.\n",
    "    \"\"\"\n",
    "    test = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            test.append(line.strip())\n",
    "    return test\n",
    "bac_test = load_test(PATH_BAC_TEST)\n",
    "news_test = load_test(PATH_NEWS_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path:str)->dict:\n",
    "    #{\"<bigram>\":{\"count\":0, \"probability\":0}}\n",
    "    \"\"\"\n",
    "    Load a model from a file.\n",
    "    Params\n",
    "    ------\n",
    "    path: str\n",
    "        Path to the file.\n",
    "    Returns\n",
    "    -------\n",
    "    model: dict\n",
    "        Dictionary with the model.\n",
    "    \"\"\"\n",
    "    model = {}\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split('\\t')\n",
    "            model[line[0]] = int(line[1])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_unk(sentence:str,monogram:dict)->str:\n",
    "    \"\"\"\n",
    "    Replace unknown words with <UNK>.\n",
    "    Params\n",
    "    ------\n",
    "    sentence: str\n",
    "        Sentence to be replaced.\n",
    "    Returns\n",
    "    -------\n",
    "    sentence: str\n",
    "        Sentence with <unk>.\n",
    "    \"\"\"\n",
    "    words = tokenizer.tokenize(sentence)\n",
    "    for word in words:\n",
    "        if word not in monogram:\n",
    "            sentence = sentence.replace(word, \"<UNK>\")\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_unigram_perplexity(model, test_data)->float:\n",
    "    \"\"\"    \n",
    "    Calculate the perplexity of a unigram model.\n",
    "    Params\n",
    "    ------\n",
    "    model: dict\n",
    "        Dictionary with the model.\n",
    "    test_data: list\n",
    "        List of strings.\n",
    "    Returns\n",
    "    -------\n",
    "    perplexity: float\n",
    "        Perplexity of the model.\n",
    "    \"\"\"\n",
    "    test_size = len(test_data)\n",
    "    log_sum = 0\n",
    "    for sentence in test_data:\n",
    "        sentence = replace_unk(sentence, model)\n",
    "        words = tokenizer.tokenize(sentence)\n",
    "        for word in words:\n",
    "            if word in model:\n",
    "                probability = model[word][\"probability\"]\n",
    "            else:\n",
    "                probability = model[\"<UNK>\"]\n",
    "            log_sum += math.log2(probability)\n",
    "    return -1*(log_sum / test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bigram_perplexity(bigram_model, monogram_model, test_data)->float:\n",
    "    \"\"\"\n",
    "    Calculate the perplexity of a bigram model.\n",
    "    Params\n",
    "    ------\n",
    "    model: dict\n",
    "        Dictionary with the model.\n",
    "    test_data: list\n",
    "        List of strings.\n",
    "    Returns\n",
    "    -------\n",
    "    perplexity: float  \n",
    "        Perplexity of the model.\n",
    "    \"\"\"\n",
    "    test_size = len(test_data)\n",
    "    log_sum = 0\n",
    "    vocabulary = len(monogram_model)\n",
    "    for sentence in test_data:\n",
    "        sentence = replace_unk(sentence, monogram_model)\n",
    "        words = tokenizer.tokenize(sentence)\n",
    "        for i in range(len(words)-1):\n",
    "            bi_gram = words[i]+\" \"+words[i+1]\n",
    "            if bi_gram in bigram_model:\n",
    "                probability = bigram_model[bi_gram][\"probability\"]\n",
    "            else:\n",
    "                probability = 1/monogram_model[words[i]][\"count\"]+vocabulary\n",
    "\n",
    "            log_sum += math.log2(probability)\n",
    "    return -1*(log_sum / test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_trigram_perplexity(trigram, bigram_model, monogram_model, test_data)->float:\n",
    "    \"\"\"\n",
    "    Calculate the perplexity of a trigram model.\n",
    "    Params\n",
    "    ------\n",
    "    model: dict\n",
    "        Dictionary with the model.\n",
    "    test_data: list\n",
    "        List of strings.\n",
    "    Returns\n",
    "    -------\n",
    "    perplexity: float  \n",
    "        Perplexity of the model.\n",
    "    \"\"\"\n",
    "    test_size = len(test_data)\n",
    "    log_sum = 0\n",
    "    vocabulary = len(monogram_model)\n",
    "    for sentence in test_data:\n",
    "        sentence = replace_unk(sentence, monogram_model)\n",
    "        words = tokenizer.tokenize(sentence)\n",
    "        for i in range(len(words)-2):\n",
    "            tri_gram = words[i]+\" \"+words[i+1]+\" \"+words[i+2]\n",
    "            bi_gram = words[i]+\" \"+words[i+1]\n",
    "            if tri_gram in trigram:\n",
    "                probability = trigram[tri_gram][\"probability\"]\n",
    "            elif bi_gram in bigram_model:\n",
    "                probability = 1/(bigram_model[bi_gram][\"count\"]+vocabulary^2)\n",
    "            else:\n",
    "                probability = 1/(1+vocabulary^2)\n",
    "            log_sum += math.log2(probability)\n",
    "    return -1*(log_sum / test_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
