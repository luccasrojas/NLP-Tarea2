{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model usage\n",
    "## Integrantes\n",
    "* Juan Esteban Arboleda\n",
    "* Luccas Rojas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculo de la perplejidad de cada modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "PATH_NEWS_UNIGRAM=\"../data/20N_l.rojasb_j.arboleda_unigrams.txt\"\n",
    "PATH_BAC_UNIGRAM=\"../data/BAC_l.rojasb_j.arboleda_unigrams.txt\"\n",
    "PATH_NEWS_BIGRAM=\"../data/20N_l.rojasb_j.arboleda_bigrams.txt\"\n",
    "PATH_BAC_BIGRAM=\"../data/BAC_l.rojasb_j.arboleda_bigrams.txt\"\n",
    "PATH_NEWS_TRIGRAM=\"../data/20N_l.rojasb_j.arboleda_trigrams.txt\"\n",
    "PATH_BAC_TRIGRAM=\"../data/BAC_l.rojasb_j.arboleda_trigrams.txt\"\n",
    "\n",
    "PATH_BAC_TEST = \"../data/BAC_l.rojasb_j.arboleda_test.txt\" \n",
    "PATH_NEWS_TEST = \"../data/20N_l.rojasb_j.arboleda_test.txt\"  \n",
    "\n",
    "tokenizer = WhitespaceTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test(path):\n",
    "    \"\"\"\n",
    "    Load test data from a file.\n",
    "    Params\n",
    "    ------\n",
    "    path: str\n",
    "        Path to the file.\n",
    "    Returns\n",
    "    -------\n",
    "    test: list\n",
    "        List of strings.\n",
    "    \"\"\"\n",
    "    test = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            test.append(line.strip())\n",
    "    return test\n",
    "bac_test = load_test(PATH_BAC_TEST)\n",
    "news_test = load_test(PATH_NEWS_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ngram(path: str) -> dict:\n",
    "    ngram_dict = {}\n",
    "    f = open(path, \"r\")\n",
    "\n",
    "    ngram = f.readline()\n",
    "    while(len(ngram) != 0):\n",
    "        ngram = ngram.split(\",\")\n",
    "        ngram_dict[ngram[0]] = {\n",
    "            \"count\": int(ngram[1]),\n",
    "            \"probability\": float(ngram[2])\n",
    "        }\n",
    "        ngram = f.readline()\n",
    "\n",
    "    return ngram_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_unk(words:list,monogram:dict)->list:\n",
    "    \"\"\"\n",
    "    Replace unknown words with <UNK>.\n",
    "    Params\n",
    "    ------\n",
    "    sentence: str\n",
    "        Sentence to be replaced.\n",
    "    Returns\n",
    "    -------\n",
    "    sentence: str\n",
    "        Sentence with <unk>.\n",
    "    \"\"\"\n",
    "    words2 = []\n",
    "    for word in words:\n",
    "        if word not in monogram:\n",
    "            words2.append(\"<UNK>\")\n",
    "        else:\n",
    "            words2.append(word)\n",
    "    return words2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_unigram_perplexity(model, test_data)->float:\n",
    "    \"\"\"    \n",
    "    Calculate the perplexity of a unigram model.\n",
    "    Params\n",
    "    ------\n",
    "    model: dict\n",
    "        Dictionary with the model.\n",
    "    test_data: list\n",
    "        List of strings.\n",
    "    Returns\n",
    "    -------\n",
    "    perplexity: float\n",
    "        Perplexity of the model.\n",
    "    \"\"\"\n",
    "    test_size = len(test_data)\n",
    "    log_sum = 0\n",
    "    for sentence in test_data:\n",
    "        words = tokenizer.tokenize(sentence)\n",
    "        words = replace_unk(words, model)\n",
    "        for word in words:\n",
    "            if word in model:\n",
    "                probability = model[word][\"probability\"]\n",
    "            else:\n",
    "                probability = model[\"<UNK>\"][\"probability\"]\n",
    "            log_sum += math.log2(probability)\n",
    "    return -(1)*(log_sum / test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bigram_perplexity(bigram_model, monogram_model, test_data)->float:\n",
    "    \"\"\"\n",
    "    Calculate the perplexity of a bigram model.\n",
    "    Params\n",
    "    ------\n",
    "    model: dict\n",
    "        Dictionary with the model.\n",
    "    test_data: list\n",
    "        List of strings.\n",
    "    Returns\n",
    "    -------\n",
    "    perplexity: float  \n",
    "        Perplexity of the model.\n",
    "    \"\"\"\n",
    "    test_size = len(test_data)\n",
    "    log_sum = 0\n",
    "    vocabulary = len(monogram_model)\n",
    "    for sentence in test_data:\n",
    "        words = tokenizer.tokenize(sentence)\n",
    "        words = replace_unk(words, monogram_model)\n",
    "        for i in range(len(words)-1):\n",
    "            bi_gram = words[i]+\" \"+words[i+1]\n",
    "            if bi_gram in bigram_model:\n",
    "                probability = bigram_model[bi_gram][\"probability\"]\n",
    "            else:\n",
    "                probability = 1/monogram_model[words[i]][\"count\"]+vocabulary\n",
    "\n",
    "            log_sum += math.log2(probability)\n",
    "    return -1*(log_sum / test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_trigram_perplexity(trigram, bigram_model, monogram_model, test_data)->float:\n",
    "    \"\"\"\n",
    "    Calculate the perplexity of a trigram model.\n",
    "    Params\n",
    "    ------\n",
    "    model: dict\n",
    "        Dictionary with the model.\n",
    "    test_data: list\n",
    "        List of strings.\n",
    "    Returns\n",
    "    -------\n",
    "    perplexity: float  \n",
    "        Perplexity of the model.\n",
    "    \"\"\"\n",
    "    test_size = len(test_data)\n",
    "    log_sum = 0\n",
    "    vocabulary = len(monogram_model)\n",
    "    for sentence in test_data:\n",
    "        words = tokenizer.tokenize(sentence)\n",
    "        words = replace_unk(words, monogram_model)\n",
    "        for i in range(len(words)-2):\n",
    "            tri_gram = words[i]+\" \"+words[i+1]+\" \"+words[i+2]\n",
    "            bi_gram = words[i]+\" \"+words[i+1]\n",
    "            if tri_gram in trigram:\n",
    "                probability = trigram[tri_gram][\"probability\"]\n",
    "            elif bi_gram in bigram_model:\n",
    "                probability = 1/(bigram_model[bi_gram][\"count\"]+vocabulary^2)\n",
    "            else:\n",
    "                probability = 1/(1+vocabulary^2)\n",
    "            log_sum += math.log2(probability)\n",
    "    return -1*(log_sum / test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224.87758482318299"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEWS_UNIGRAMS_PATH  = \"../data/20N_l.rojasb_j.arboleda_unigrams.txt\"\n",
    "NEWS_BIGRAM_PATH    = \"../data/20N_l.rojasb_j.arboleda_bigrams.txt\"\n",
    "NEWS_TRIGRAM_PATH   = \"../data/20N_l.rojasb_j.arboleda_trigrams.txt\"\n",
    "\n",
    "unigrams_model = load_ngram(NEWS_UNIGRAMS_PATH)\n",
    "calculate_unigram_perplexity(unigrams_model, news_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156.84539064251038"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_model = load_ngram(NEWS_BIGRAM_PATH)\n",
    "calculate_bigram_perplexity(bigram_model, unigrams_model, news_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294.29830390896524"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_model = load_ngram(NEWS_TRIGRAM_PATH)\n",
    "calculate_trigram_perplexity(trigram_model, bigram_model, unigrams_model, news_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
